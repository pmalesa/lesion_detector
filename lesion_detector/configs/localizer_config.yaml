data_dir: "../data"
metadata_path: "../data/deeplesion_metadata.csv"

environment:
  render: true
  max_steps: 100                        # Max steps the agent can take before the episode ends
  bbox_move_step_factor: 0.1
  bbox_resize_factor: 0.1
  initial_bbox_width: 320
  initial_bbox_height: 320
  bbox_pixel_margin: 10                 # Number of margin pixels around the bounding box (in every direction)
  bbox_min_length: 10                   # Minimal bounding box width/height
  bbox_max_length: 64                   # Maximal bounding box width/height
  bbox_max_aspect_ratio: 3.0            # Maximal aspect ratio of the bounding box
  bbox_randomize: true
  bbox_position_shift_range: 64         # Value by which x or y coordinate of the bounding box can vary in both directions when initialized
  bbox_size_shift_range: 10             # Value by which width and height of the bounding box can vary when initialized
  n_previous_actions: 10                # Number of previous actions stored in the observation
  iou_threshold: 0.7

  reward:
    alpha_1: 1.0                        # Weight of the IoU reward component
    alpha_2: 3.0                        # Weight of the delta IoU reward component (2.0 - 3.0)
    beta: 5.0                           # Weight of the delta distance reward component  (5.0 - 10.0)
    step_penalty: -0.1                  # (-0.05 - -0.02)
    iou_final_reward: 20.0              # Additional, big reward on finishing step, when IoU >= threshold (20.0 - 30.0)

agent:
  learning_rate: 0.0001
  gamma: 0.99                           # discount factor
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 1500                   # Number of global steps (not episodes!) after which the epsilon will reach its minimum value
  replay_buffer_size: 10000
  target_update_steps: 500              # Number of steps after which the target network is updated
  batch_size: 64 # 64
  fixed_patch_length: 64                # Fixed length (widht/height) of the patch (input width/height of the CNN) 

train:
  train_episodes: 500
  log_interval: 1                       # print/log progress every x episodes
  save_interval: 50                     # chackpoint model every x episodes
  output_dir: "../runs/localizer"       # path for saving logs, checkpoints etc.

test:
  test_episodes: 20
  model_checkpoint: "../runs/localizer/checkpoints/agent_lastest.pt"

logging:
  level: INFO
  format: "(%(asctime)s) %(name)s [%(levelname)s]: %(message)s"
  datefmt: "%Y-%m-%d %H:%M:%S"