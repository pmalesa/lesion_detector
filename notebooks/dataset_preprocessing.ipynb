{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad82646",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing\n",
    "\n",
    "This notebook is dedicated to preprocess the given dataset into a required format/structure and divide it into train/val/test splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac67d88",
   "metadata": {},
   "source": [
    "# Google Colab only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b5a33",
   "metadata": {},
   "source": [
    "### Download required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/pmalesa/lesion_detector/main/notebooks/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8a0f5",
   "metadata": {},
   "source": [
    "### Mount DeepLesion images and checkpoints from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content\n",
    "\n",
    "# remove existing link if any\n",
    "!rm -rf data/deeplesion\n",
    "!rm -rf faster_rcnn_checkpoints\n",
    "\n",
    "!mkdir -p data\n",
    "!ln -s /content/drive/MyDrive/deeplesion/data/deeplesion data/deeplesion\n",
    "!ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901fb48",
   "metadata": {},
   "source": [
    "# Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from typing import Any\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32778b",
   "metadata": {},
   "source": [
    "# Image preprocessing and utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afee5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads metadata from the given path and\n",
    "    returns it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def normalize(img: NDArray[np.uint16], per_image_norm: bool):\n",
    "    \"\"\"\n",
    "    Normalizes the input image\n",
    "    \"\"\"\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    if not per_image_norm:\n",
    "        return img / 65535.0\n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    img = (img - min) / (max - min)\n",
    "    return img\n",
    "\n",
    "def convert_to_hu(img: NDArray[np.uint16], norm: bool, hu_min=-1024, hu_max=3071):\n",
    "    \"\"\"\n",
    "    Converts the pixel data of a uint16\n",
    "    CT image to Hounsfield Units (HU).\n",
    "    \"\"\"\n",
    "\n",
    "    hu_img = img.astype(np.int32) - 32768\n",
    "    hu_img = np.clip(hu_img, hu_min, hu_max).astype(np.float32)\n",
    "    if norm:\n",
    "        hu_img = (hu_img - hu_min) / (hu_max - hu_min)\n",
    "        hu_img = np.clip(hu_img, 0.0, 1.0)\n",
    "    return hu_img\n",
    "\n",
    "def load_image(path: str, hu_scale: bool = True, norm: bool = True, per_image_norm: bool = True):\n",
    "    \"\"\"\n",
    "    Loads an image given its path\n",
    "    and returns it as a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    img_array = np.array(img)\n",
    "    if hu_scale:\n",
    "        hu_min = -160\n",
    "        hu_max = 240\n",
    "        return convert_to_hu(img_array, norm, hu_min, hu_max)\n",
    "    elif norm:\n",
    "        return normalize(img_array, per_image_norm)\n",
    "    return img_array\n",
    "\n",
    "def save_image(img_array: NDArray[Any], path: str):\n",
    "    \"\"\"\n",
    "    Saves the input image to the specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    if img_array.dtype != np.uint16:\n",
    "        img_array = img_array.astype(np.uint16)\n",
    "    img = Image.fromarray(img_array)\n",
    "    img.save(path)\n",
    "\n",
    "def save_normalized_image_uint8(img_array: NDArray[Any], path: str):\n",
    "    \"\"\"\n",
    "    Saves the normalized input image data (0.0 - 1.0) \n",
    "    to the specified path with uint8 precision (0 - 255).\n",
    "    \"\"\"\n",
    "\n",
    "    img_array_scaled = (img_array * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    img = Image.fromarray(img_array_scaled)\n",
    "    img.save(path)\n",
    "\n",
    "def show_image(img: NDArray[np.float32], title=\"Example Image\", cmap=\"gray\"):\n",
    "    \"\"\"\n",
    "    Shows the image given its data, title and colour map.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661233b",
   "metadata": {},
   "source": [
    "# Set paths to DeepLesion images and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b984d",
   "metadata": {},
   "source": [
    "## Paths to unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab\n",
    "deeplesion_metadata_path = Path(\"data/deeplesion/deeplesion_metadata.csv\")\n",
    "deeplesion_image_path = Path(\"data/deeplesion/key_slices/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e05908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "deeplesion_metadata_path = Path(\"../data/deeplesion_metadata.csv\")\n",
    "deeplesion_image_path = Path(\"../data/deeplesion/key_slices/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cf544",
   "metadata": {},
   "source": [
    "## Paths to processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_data_dir = Path(\"data/deeplesion/\")\n",
    "deeplesion_preprocessed_image_path = deeplesion_data_dir / \"deeplesion_preprocessed_uint8/key_slices\"\n",
    "deeplesion_preprocessed_metadata_path = deeplesion_data_dir / \"deeplesion_preprocessed_uint8/deeplesion_metadata_preprocessed.csv\"\n",
    "\n",
    "# Path to deeplesion metadata in COCO format\n",
    "deeplesion_coco_json_path = deeplesion_data_dir / \"deeplesion_coco.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886b3ffe",
   "metadata": {},
   "source": [
    "# Preprocess the DeepLesion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37851b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the DeepLesion dataset by:\n",
    "    - Choosing only images that come from the original validation and test set divisions (only these have lesion type annotations),\n",
    "    - Normalizing each image according to a fixed HU scale window [-160, 240] (can be also [-1024, 3071]),\n",
    "    - Resizing each image to 512x512 if necessary (and adjusting the target bounding box coordinates),\n",
    "    - Saving the new metadata file with resized images and adjusted target bounding boxes. \n",
    "'''\n",
    "\n",
    "deeplesion_metadata = load_metadata(deeplesion_metadata_path)\n",
    "\n",
    "# Clear the existing directory with preprocessed images\n",
    "if deeplesion_preprocessed_image_path.exists() and deeplesion_preprocessed_image_path.is_dir():\n",
    "    shutil.rmtree(deeplesion_preprocessed_image_path)\n",
    "deeplesion_preprocessed_image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx, row in deeplesion_metadata.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "    image_path = os.path.join(deeplesion_image_path, file_name)\n",
    "    preprocessed_image_path = os.path.join(deeplesion_preprocessed_image_path, file_name)\n",
    "    image_data = load_image(image_path)\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    # Extract sizes\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "\n",
    "    # Rescale to (512 x 512) if necessary\n",
    "    if (width, height) != (512, 512):\n",
    "        image_data = cv2.resize(\n",
    "            image_data, (512, 512), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        scale_x = 512 / width\n",
    "        scale_y = 512 / height\n",
    "        x1 = round(x1 * scale_x)\n",
    "        y1 = round(y1 * scale_y)\n",
    "        x2 = round(x2 * scale_x)\n",
    "        y2 = round(y2 * scale_y)\n",
    "        height = 512\n",
    "        width = 512\n",
    "\n",
    "        deeplesion_metadata.at[idx, \"Bounding_boxes\"] = f\"{x1}, {y1}, {x2}, {y2}\"\n",
    "        deeplesion_metadata.at[idx, \"Image_size\"] = \"512, 512\"\n",
    "\n",
    "    save_normalized_image_uint8(image_data, preprocessed_image_path)    \n",
    "\n",
    "# Save preprocessed metadata csv file\n",
    "deeplesion_metadata.to_csv(deeplesion_preprocessed_metadata_path)\n",
    "\n",
    "# Verify if all images have 512x512 size\n",
    "deeplesion_metadata_preprocessed = load_metadata(deeplesion_preprocessed_metadata_path)\n",
    "for idx, row in deeplesion_metadata_preprocessed.iterrows():\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "    size_str = row[\"Image_size\"]\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "    if (width, height) != (512, 512):\n",
    "        raise ValueError(f\"ERROR: Not all images have required size!\")\n",
    "print(f\"SUCCES: All images were preprocessed correctly.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc4fda",
   "metadata": {},
   "source": [
    "# Convert DeepLesion metadata to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_metadata_preprocessed = load_metadata(deeplesion_preprocessed_metadata_path)\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "categories = [\n",
    "    {\"id\": 1, \"name\": \"bone\"},\n",
    "    {\"id\": 2, \"name\": \"abdomen\"},\n",
    "    {\"id\": 3, \"name\": \"mediastinum\"},\n",
    "    {\"id\": 4, \"name\": \"liver\"},\n",
    "    {\"id\": 5, \"name\": \"lung\"},\n",
    "    {\"id\": 6, \"name\": \"kidney\"},\n",
    "    {\"id\": 7, \"name\": \"soft tissue\"},\n",
    "    {\"id\": 8, \"name\": \"pelvis\"}\n",
    "]\n",
    "\n",
    "image_counter = 1\n",
    "annotation_id = 1\n",
    "image_id_map = {}\n",
    "\n",
    "for idx, row in deeplesion_metadata_preprocessed.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    lesion_type = row[\"Coarse_lesion_type\"]\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    # Extract sizes\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "\n",
    "    # Register image\n",
    "    if file_name not in image_id_map:\n",
    "        image_id_map[file_name] = image_counter\n",
    "        images.append({\n",
    "            \"id\": image_counter,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        image_counter += 1\n",
    "    image_id = image_id_map[file_name]\n",
    "\n",
    "    # Initialize ground truth bounding box' parameters\n",
    "    bbox = [x1, y1, x2 - x1, y2 - y1]\n",
    "    area = bbox[2] * bbox[3]\n",
    "\n",
    "    annotations.append({\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category\": lesion_type,\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": area,\n",
    "        \"iscrowd\": 0    # Normal object (not crowd of indistinct objects, that can't be cleanly separated)\n",
    "    })\n",
    "\n",
    "    annotation_id += 1\n",
    "\n",
    "# Save to JSON\n",
    "deeplesion_coco_format = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "with open(deeplesion_coco_json_path, \"w\") as f:\n",
    "    json.dump(deeplesion_coco_format, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5c7c6",
   "metadata": {},
   "source": [
    "# Convert DeepLesion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58be9da",
   "metadata": {},
   "source": [
    "## Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this seed to create different train/val/test splits (42, 314, 666)\n",
    "current_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504d130",
   "metadata": {},
   "source": [
    "## YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_metadata_preprocessed = load_metadata(deeplesion_preprocessed_metadata_path)\n",
    "\n",
    "# Source directories\n",
    "image_dir = deeplesion_preprocessed_image_path\n",
    "label_dir = deeplesion_data_dir / \"labels_unsorted\"\n",
    "\n",
    "# Create .txt files\n",
    "label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target directory\n",
    "target_dir = deeplesion_data_dir / \"deeplesion_yolo\"\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "for idx, row in deeplesion_metadata_preprocessed.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    image_path = os.path.join(str(image_dir), file_name)\n",
    "    label_path = os.path.join(str(label_dir), file_name.replace(\".png\", \".txt\"))\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    lesion_type = row[\"Coarse_lesion_type\"] - 1 # YOLOv5 requires class IDs starting at 0\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    # Extract sizes\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "\n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    x_center = x1 + bbox_width / 2\n",
    "    y_center = y1 + bbox_height / 2\n",
    "\n",
    "    # Normalize\n",
    "    x_center /= width\n",
    "    y_center /= height\n",
    "    bbox_width /= width\n",
    "    bbox_height /= height\n",
    "\n",
    "    with open(label_path, 'a') as f:\n",
    "        f.write(f\"{lesion_type} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    (target_dir / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    (target_dir / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images with annotated lesions\n",
    "annotated_images = [img for img in image_dir.glob(\"*.png\") if (label_dir / (img.stem + \".txt\")).exists()]\n",
    "random.seed(current_seed)\n",
    "random.shuffle(annotated_images)\n",
    "\n",
    "# Split into train, val and test sets\n",
    "n_total = len(annotated_images)\n",
    "n_train = int(0.7 * n_total)\n",
    "n_val = int(0.15 * n_total)\n",
    "\n",
    "train_images = annotated_images[:n_train]\n",
    "val_images = annotated_images[n_train:n_train + n_val]\n",
    "test_images = annotated_images[n_train + n_val:]\n",
    "\n",
    "splits_map = {\n",
    "    \"train\": train_images,\n",
    "    \"val\": val_images,\n",
    "    \"test\": test_images\n",
    "}\n",
    "\n",
    "# Copy image files\n",
    "for split, images in splits_map.items():\n",
    "    for image_path in images:\n",
    "        label_path = label_dir / (image_path.stem + \".txt\")\n",
    "        shutil.copy(image_path, target_dir / \"images\" / split / image_path.name)\n",
    "        shutil.copy(label_path, target_dir / \"labels\" / split / label_path.name)\n",
    "\n",
    "print(f\"Split done! Total = {n_total}\")\n",
    "\n",
    "# Generate deeplesion.yaml\n",
    "dataset_root = os.path.abspath(str(target_dir))\n",
    "deeplesion_yaml = {\n",
    "    \"path\": dataset_root,\n",
    "    \"train\": os.path.join(dataset_root, \"images/train\"),\n",
    "    \"val\": os.path.join(dataset_root, \"images/val\"),\n",
    "    \"test\": os.path.join(dataset_root, \"images/test\"),\n",
    "    \"nc\": 8,\n",
    "    \"names\": [\n",
    "        \"bone\",\n",
    "        \"abdomen\",\n",
    "        \"mediastinum\",\n",
    "        \"liver\",\n",
    "        \"lung\",\n",
    "        \"kidney\",\n",
    "        \"soft_tissue\",\n",
    "        \"pelvis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(target_dir / \"deeplesion.yaml\", \"w\") as f:\n",
    "    yaml.dump(deeplesion_yaml, f)\n",
    "\n",
    "# Remove directory with unsorted labels\n",
    "if label_dir.exists() and label_dir.is_dir():\n",
    "    shutil.rmtree(label_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b96b3f",
   "metadata": {},
   "source": [
    "## Faster R-CNN format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_metadata_preprocessed = load_metadata(deeplesion_preprocessed_metadata_path)\n",
    "\n",
    "# Source directories\n",
    "image_dir = deeplesion_preprocessed_image_path\n",
    "label_dir = deeplesion_data_dir / \"labels_unsorted\"\n",
    "\n",
    "# Create .txt files\n",
    "label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target directory\n",
    "target_dir = deeplesion_data_dir / \"deeplesion_fasterrcnn_split_X\"  # \"X\" is to be replaced with a number 1-3\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "for idx, row in deeplesion_metadata_preprocessed.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    image_path = os.path.join(str(image_dir), file_name)\n",
    "    label_path = os.path.join(str(label_dir), file_name.replace(\".png\", \".txt\"))\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    lesion_type = row[\"Coarse_lesion_type\"] # Faster R-CNN uses the class 0 implicitly as the background class (no need for subtraction)\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    with open(label_path, 'a') as f:\n",
    "        f.write(f\"{lesion_type} {x1} {y1} {x2} {y2}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    (target_dir / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    (target_dir / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images with annotated lesions\n",
    "annotated_images = [img for img in image_dir.glob(\"*.png\") if (label_dir / (img.stem + \".txt\")).exists()]\n",
    "random.seed(current_seed)\n",
    "random.shuffle(annotated_images)\n",
    "\n",
    "# Split into train, val and test sets\n",
    "n_total = len(annotated_images)\n",
    "n_train = int(0.7 * n_total)\n",
    "n_val = int(0.15 * n_total)\n",
    "\n",
    "train_images = annotated_images[:n_train]\n",
    "val_images = annotated_images[n_train:n_train + n_val]\n",
    "test_images = annotated_images[n_train + n_val:]\n",
    "\n",
    "splits_map = {\n",
    "    \"train\": train_images,\n",
    "    \"val\": val_images,\n",
    "    \"test\": test_images\n",
    "}\n",
    "\n",
    "# Copy image files\n",
    "for split, images in splits_map.items():\n",
    "    for image_path in images:\n",
    "        label_path = label_dir / (image_path.stem + \".txt\")\n",
    "        shutil.copy(image_path, target_dir / \"images\" / split / image_path.name)\n",
    "        shutil.copy(label_path, target_dir / \"labels\" / split / label_path.name)\n",
    "\n",
    "print(f\"Split done! Total = {n_total}\")\n",
    "\n",
    "# Remove directory with unsorted labels\n",
    "if label_dir.exists() and label_dir.is_dir():\n",
    "    shutil.rmtree(label_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lesion_detector_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
