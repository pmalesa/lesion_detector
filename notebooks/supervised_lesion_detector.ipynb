{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad82646",
   "metadata": {},
   "source": [
    "# Supervised Lesion Detector\n",
    "\n",
    "This notebook is dedicated to training and evaluating a supervised lesion detector on DeepLesion dataset with the following supervised model architectures for image detection with ResNet-50 backbone:\n",
    "- YOLOv5 (stable, but YOLOv8 is newer),\n",
    "- Faster R-CNN (torchvision.models.detection or Detectron2),\n",
    "- DETR (Facebook DETR),\n",
    "- Improved DETR (DINO-DETR or Deformable DETR, DINO has better performance but Deformable is faster),\n",
    "- RetinaNet (FPN backbone + anchor-based).\n",
    "\n",
    "## Assumptions:\n",
    "- Use 2D slice inputs (optionally use the neighbouring ones too),\n",
    "- Resize all images to 512x512,\n",
    "- Use COCO-style Dataset class.\n",
    "- Use DeepLesion for training a general lesion localizer and some other like LiTS (Liver Tumor Segmentation) or CHAOS (CT liver dataset) for more specialized localizer.\n",
    "\n",
    "## ðŸ“š Thesis Value Summary\n",
    "### Contribution and Value:\n",
    "- Comparison of CNN vs Transformer detectors on DeepLesion\t-> âœ… Fills a gap in literature\n",
    "- Evaluation of improved DETRs (DINO/Deformable) -> âœ… Modern insight\n",
    "- General vs specialized lesion detection -> âœ… Strong clinical relevance\n",
    "- Analysis of training time, robustness, failure modes -> âœ… Engineering depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901fb48",
   "metadata": {},
   "source": [
    "# Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from typing import Any\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32778b",
   "metadata": {},
   "source": [
    "# Image utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afee5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads metadata from the given path and\n",
    "    returns it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def normalize(img: NDArray[np.uint16], per_image_norm: bool):\n",
    "    \"\"\"\n",
    "    Normalizes the input image\n",
    "    \"\"\"\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    if not per_image_norm:\n",
    "        return img / 65535.0\n",
    "    max = np.max(img)\n",
    "    min = np.min(img)\n",
    "    img = (img - min) / (max - min)\n",
    "    return img\n",
    "\n",
    "def convert_to_hu(img: NDArray[np.uint16], norm: bool, hu_min=-1024, hu_max=3071):\n",
    "    \"\"\"\n",
    "    Converts the pixel data of a uint16\n",
    "    CT image to Hounsfield Units (HU).\n",
    "    \"\"\"\n",
    "\n",
    "    hu_img = img.astype(np.int32) - 32768\n",
    "    hu_img = np.clip(hu_img, hu_min, hu_max).astype(np.float32)\n",
    "    if norm:\n",
    "        hu_img = (hu_img - hu_min) / (hu_max - hu_min)\n",
    "        hu_img = np.clip(hu_img, 0.0, 1.0)\n",
    "    return hu_img\n",
    "\n",
    "def load_image(path: str, hu_scale: bool = True, norm: bool = True, per_image_norm: bool = True):\n",
    "    \"\"\"\n",
    "    Loads an image given its path\n",
    "    and returns it as a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    img_array = np.array(img)\n",
    "    if hu_scale:\n",
    "        hu_min = -160\n",
    "        hu_max = 240\n",
    "        return convert_to_hu(img_array, norm, hu_min, hu_max)\n",
    "    elif norm:\n",
    "        return normalize(img_array, per_image_norm)\n",
    "    return img_array\n",
    "\n",
    "def save_image(img_array: NDArray[Any], path: str):\n",
    "    \"\"\"\n",
    "    Saves the input image to the specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    if img_array.dtype != np.uint16:\n",
    "        img_array = img_array.astype(np.uint16)\n",
    "    img = Image.fromarray(img_array)\n",
    "    img.save(path)\n",
    "\n",
    "def show_image(img: NDArray[np.float32], title=\"Example Image\", cmap=\"gray\"):\n",
    "    \"\"\"\n",
    "    Shows the image given its data, title and colour map.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc4fda",
   "metadata": {},
   "source": [
    "# Convert DeepLesion metadata to COCO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_metadata = load_metadata(\"../data/deeplesion_metadata.csv\")\n",
    "deeplesion_image_path = \"../data/deeplesion/key_slices/\"\n",
    "deeplesion_coco_json_path = \"../data/deeplesion_coco.json\"\n",
    "\n",
    "images = []\n",
    "annotations = []\n",
    "categories = [\n",
    "    {\"id\": 1, \"name\": \"bone\"},\n",
    "    {\"id\": 2, \"name\": \"abdomen\"},\n",
    "    {\"id\": 3, \"name\": \"mediastinum\"},\n",
    "    {\"id\": 4, \"name\": \"liver\"},\n",
    "    {\"id\": 5, \"name\": \"lung\"},\n",
    "    {\"id\": 6, \"name\": \"kidney\"},\n",
    "    {\"id\": 7, \"name\": \"soft tissue\"},\n",
    "    {\"id\": 8, \"name\": \"pelvis\"}\n",
    "]\n",
    "\n",
    "image_counter = 1\n",
    "annotation_id = 1\n",
    "image_id_map = {}\n",
    "\n",
    "for idx, row in deeplesion_metadata.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    lesion_type = row[\"Coarse_lesion_type\"]\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "    image_path = os.path.join(deeplesion_image_path, file_name)\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    # Extract sizes\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "\n",
    "    # Register image\n",
    "    if file_name not in image_id_map:\n",
    "        image_id_map[file_name] = image_counter\n",
    "        images.append({\n",
    "            \"id\": image_counter,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "        image_counter += 1\n",
    "    image_id = image_id_map[file_name]\n",
    "\n",
    "    # Initialize ground truth bounding box' parameters\n",
    "    bbox = [x1, y1, x2 - x1, y2 - y1]\n",
    "    area = bbox[2] * bbox[3]\n",
    "\n",
    "    annotations.append({\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category\": lesion_type,\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": area,\n",
    "        \"iscrowd\": 0    # Normal object (not crowd of indistinct objects, that can't be cleanly separated)\n",
    "    })\n",
    "\n",
    "    annotation_id += 1\n",
    "\n",
    "# Save to JSON\n",
    "deeplesion_coco_format = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}\n",
    "\n",
    "with open(deeplesion_coco_json_path, \"w\") as f:\n",
    "    json.dump(deeplesion_coco_format, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5c7c6",
   "metadata": {},
   "source": [
    "# Convert DeepLesion metadata to text files required by YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplesion_metadata = load_metadata(\"../data/deeplesion_metadata.csv\")\n",
    "\n",
    "# Source directories\n",
    "image_dir = Path(\"../data/deeplesion/key_slices/\")\n",
    "label_dir = Path(\"labels_unsorted/\")\n",
    "\n",
    "# Create .txt files\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "for idx, row in deeplesion_metadata.iterrows():\n",
    "    # Extract only images with annotated lesions (Val + Test)\n",
    "    if row[\"Train_Val_Test\"] == 1:\n",
    "        continue\n",
    "\n",
    "    file_name = row[\"File_name\"]\n",
    "    image_path = os.path.join(str(image_dir), file_name)\n",
    "    label_path = os.path.join(str(label_dir), file_name.replace(\".png\", \".txt\"))\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    lesion_type = row[\"Coarse_lesion_type\"] - 1 # YOLOv5 requires class IDS starting at 0\n",
    "    bbox_str = row[\"Bounding_boxes\"]\n",
    "    size_str = row[\"Image_size\"]\n",
    "\n",
    "    # Extract ground truth bounding box' coordinates\n",
    "    bbox_coords = [float(val) for val in bbox_str.split(\",\")]\n",
    "    x1, y1, x2, y2 = [round(c) for c in bbox_coords]\n",
    "\n",
    "    # Extract sizes\n",
    "    image_sizes = [int(val) for val in size_str.split(\",\")]\n",
    "    width, height = [size for size in image_sizes]\n",
    "\n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    x_center = x1 + bbox_width / 2\n",
    "    y_center = y1 + bbox_height / 2\n",
    "\n",
    "    # Normalize\n",
    "    x_center /= width\n",
    "    y_center /= height\n",
    "    bbox_width /= width\n",
    "    bbox_height /= height\n",
    "\n",
    "    with open(label_path, 'a') as f:\n",
    "        f.write(f\"{lesion_type} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Create target structure\n",
    "target_dir = Path(\"deeplesion_yolo\")\n",
    "if target_dir.exists() and target_dir.is_dir():\n",
    "    shutil.rmtree(target_dir)\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    (target_dir / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    (target_dir / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images with annotated lesions\n",
    "annotated_images = [img for img in image_dir.glob(\"*.png\") if (label_dir / (img.stem + \".txt\")).exists()]\n",
    "random.shuffle(annotated_images)\n",
    "\n",
    "# Split into train, val and test sets\n",
    "n_total = len(annotated_images)\n",
    "n_train = int(0.7 * n_total)\n",
    "n_val = int(0.15 * n_total)\n",
    "\n",
    "train_images = annotated_images[:n_train]\n",
    "val_images = annotated_images[n_train:n_train + n_val]\n",
    "test_images = annotated_images[n_train + n_val:]\n",
    "\n",
    "splits_map = {\n",
    "    \"train\": train_images,\n",
    "    \"val\": val_images,\n",
    "    \"test\": test_images\n",
    "}\n",
    "\n",
    "# TODO - PERFORM NORMALIZATION ACCORDING TO HU SCALE HERE\n",
    "# Copy image files\n",
    "for split, images in splits_map.items():\n",
    "    for image_path in images:\n",
    "        label_path = label_dir / (image_path.stem + \".txt\")\n",
    "        shutil.copy(image_path, target_dir / \"images\" / split / image_path.name)\n",
    "        shutil.copy(label_path, target_dir / \"labels\" / split / label_path.name)\n",
    "\n",
    "print(f\"Split done! Total = {n_total}\")\n",
    "\n",
    "# Generate deeplesion.yaml\n",
    "dataset_root = os.path.abspath(str(target_dir))\n",
    "deeplesion_yaml = {\n",
    "    \"path\": dataset_root,\n",
    "    \"train\": os.path.join(dataset_root, \"images/train\"),\n",
    "    \"val\": os.path.join(dataset_root, \"images/val\"),\n",
    "    \"test\": os.path.join(dataset_root, \"images/test\"),\n",
    "    \"nc\": 8,\n",
    "    \"names\": [\n",
    "        \"bone\",\n",
    "        \"abdomen\",\n",
    "        \"mediastinum\",\n",
    "        \"liver\",\n",
    "        \"lung\",\n",
    "        \"kidney\",\n",
    "        \"soft_tissue\",\n",
    "        \"pelvis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(target_dir / \"deeplesion.yaml\", \"w\") as f:\n",
    "    yaml.dump(deeplesion_yaml, f)\n",
    "\n",
    "# Remove directory with unsorted labels\n",
    "if label_dir.exists() and label_dir.is_dir():\n",
    "    shutil.rmtree(label_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773382b3",
   "metadata": {},
   "source": [
    "# Train and evaluate YOLOv5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained YOLOv5 model\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5233598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the YOLOv5 model on the DeepLesion dataset\n",
    "!python yolov5/train.py --img 512 --batch 8 --epochs 100 --data deeplesion_yolo/deeplesion.yaml --weights yolov5s.pt --name deeplesion_yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the YOLOv5 model\n",
    "!python yolov5/val.py --data deeplesion_yolo/deeplesion.yaml --weights yolov5/runs/train/deeplesion_yolov5/weights/best.pt --img 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lesion_detector_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
