data_dir: "data/"
images_dir: "data/deeplesion/key_slices/"
metadata_path: "data/deeplesion_metadata.csv"
models_dir: "models/"
backbone_cnn_path: "models/backbone_cnn_finetuned.pth"

regression:
  learning_rate: 0.0001
  log_interval: 1
  epochs: 10

environment:
  render: false
  max_steps: 30                         # Max steps the agent can take before the episode ends
  bbox_move_step_factor: 0.1
  bbox_resize_factor: 0.1
  initial_bbox_width: 512
  initial_bbox_height: 512
  bbox_pixel_margin: 10                 # Number of margin pixels around the bounding box (in every direction)
  bbox_min_length: 10                   # Minimal bounding box width/height
  bbox_max_length: 64                   # Maximal bounding box width/height
  bbox_max_aspect_ratio: 3.0            # Maximal aspect ratio of the bounding box
  bbox_randomize: false
  bbox_position_shift_range: 64         # Value by which x or y coordinate of the bounding box can vary in both directions when initialized
  bbox_size_shift_range: 10             # Value by which width and height of the bounding box can vary when initialized
  iou_threshold: 0.5
  iou_terminate_threshold: 0.8          # Value of IoU after which the episode is terminated automatically

  reward:
    step_penalty: 0.1                   # (0.05 - 0.1)
    iou_final_reward: 20.0              # Additional, big reward on finishing step, when IoU >= threshold
    illegal_action_penalty: 5.0         # Penalty for choosing an illegal action (-1.0 or -5.0) 

agent:
  learning_rate: 0.0001
  gamma: 0.9                            # Discount factor
  tau: 1.0                              # Soft-update coefficient (1.0 - hard update)
  n_steps: 3                            # n-steps rewards (n-step TD backup)
  train_freq: 1                         # Update frequency - determines how often we perform the gradient update (in steps)
  epsilon_start: 0.75
  epsilon_end: 0.01
  epsilon_decay: 0.02                   # Fraction of all timesteps after which the epsilon will reach its minimum value
  replay_buffer_size: 100000
  target_update_steps: 1000             # Number of steps after which the target network is updated
  batch_size: 32
  fixed_patch_length: 224     # 128     # Fixed length (widht/height) of the patch (input width/height of the CNN) 

train:
  episodes_per_image: 40                # Number of episodes per image (~epochs)
  n_train_images: 300                     # Total number of images used for training
  train_steps: 1000000                  # Should be between 500k and 1M
  log_interval: 1                       # Print/log progress every x episodes
  save_interval: 50                     # Checkpoint model every x episodes
  output_dir: "runs/"                   # Path for saving logs, checkpoints etc.

# TODO
test:
  test_episodes: 20                     
  success_iou: 0.4
  model_checkpoint: "../runs/localizer/checkpoints/agent_lastest.pt"

logging:
  level: INFO
  format: "(%(asctime)s) %(name)s [%(levelname)s]: %(message)s"
  datefmt: "%Y-%m-%d %H:%M:%S"